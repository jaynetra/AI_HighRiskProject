{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J2cMCuBgqNP"
      },
      "source": [
        "**Value-Based Healthcare (VBHC) in Breast Reconstruction Surgery**\n",
        "\n",
        "This notebook demonstrates how to use a Retrieval-Augmented Generation (RAG) pipeline to extract structured clinical insights from PubMed articles. It walks through loading PDFs, embedding them into a FAISS vector store, and querying the content using GPT-4 to support evidence-based analysis of breast reconstruction outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SZf4Vulg1yw"
      },
      "source": [
        "**Install Required Dependencies**\n",
        "\n",
        "These packages are required to build a Retrieval-Augmented Generation (RAG) pipeline.\n",
        "\n",
        "langchain provides tools to load, split, embed, and query documents.\n",
        "\n",
        "openai connects to GPT-4 for generating answers and embeddings.\n",
        "\n",
        "faiss-cpu stores document embeddings and enables fast semantic search.\n",
        "\n",
        "PyPDF2 extracts text from research PDFs.\n",
        "\n",
        "tiktoken manages token counts to ensure compatibility with model input limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKfJAOgdWpag",
        "outputId": "4ffe50b4-4ec3-462b-e7f5-3985db5ae5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2, faiss-cpu, tiktoken\n",
            "Successfully installed PyPDF2-3.0.1 faiss-cpu-1.10.0 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai faiss-cpu PyPDF2 tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyo59vCxh-n6"
      },
      "source": [
        "**Mount Google Drive**\n",
        "\n",
        "We mount Google Drive to access research PDFs stored in the cloud. This allows us to load documents directly from your Drive folder into the notebook, so we can process them, embed them, and use them for question answering with the RAG pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3Hi0_vJXDln",
        "outputId": "ea795a9e-143f-4a96-f000-52dfaf7ba559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFTNwv24iXxM"
      },
      "source": [
        "**Locate and List PDF Files in Google Drive**\n",
        "\n",
        "In this step, we define the path to the folder in Google Drive that contains our PubMed research PDFs. We then list all PDF files in that folder using Python’s os module. This prepares the documents for loading and processing in the next steps of the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8pI8TzkHXyaP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "pdf_folder = \"/content/drive/MyDrive/Project Work/RAG_PDFs\"\n",
        "pdf_files = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ_8qTiyiyVm"
      },
      "source": [
        "**Upgrade PDF Processing Dependencies**\n",
        "\n",
        "In this step, we upgrade to the latest version of the langchain-community package and install pypdf, which is required for reliable PDF parsing in LangChain. This ensures we have access to the latest document loaders and robust handling of scientific PDFs, which is crucial for accurate chunking and embedding later in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H4TDxS2YO20",
        "outputId": "fca37b17-bfb5-4f7d-8e48-76323bd37d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.52)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, pypdf, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.9.1 pypdf-5.4.0 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cWttsNQjKuz"
      },
      "source": [
        "**Load and Split PDF Documents into Chunks**\n",
        "\n",
        "In this step, we use LangChain’s PyPDFLoader to load each research article and extract its text. Then, we split each document into overlapping chunks using RecursiveCharacterTextSplitter. This is important because language models like GPT-4 have context length limits, so breaking the documents into manageable pieces ensures we can embed and retrieve them effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZoY7ieIYHTZ",
        "outputId": "7d027aac-78bb-4aa0-92a3-0629051a967d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 618\n"
          ]
        }
      ],
      "source": [
        "# Import necessary classes from LangChain\n",
        "from langchain.document_loaders import PyPDFLoader  # Used to load and extract text from PDF files\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Used to split long texts into manageable chunks\n",
        "\n",
        "# Initialize an empty list to store all the document chunks\n",
        "all_chunks = []\n",
        "\n",
        "# Loop through a list of PDF file paths\n",
        "for file in pdf_files:\n",
        "    # Load the content of each PDF file\n",
        "    loader = PyPDFLoader(file)\n",
        "    docs = loader.load()  # Extracts all the text from the PDF and returns it as documents\n",
        "\n",
        "    # Initialize the text splitter\n",
        "    # Each chunk will have up to 1000 characters with a 200-character overlap between consecutive chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "    # Split the loaded documents into smaller overlapping chunks\n",
        "    chunks = splitter.split_documents(docs)\n",
        "\n",
        "    # Add the generated chunks to the overall list\n",
        "    all_chunks.extend(chunks)\n",
        "\n",
        "# Print the total number of chunks created across all PDFs\n",
        "print(f\"Total chunks created: {len(all_chunks)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lrSyAlmFYx8R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-.......\"  # os.environ[\"OPENAI_API_KEY\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJF9434KjdRd"
      },
      "source": [
        "**Generate Embeddings and Store in FAISS Vector Database**\n",
        "\n",
        "In this step, we convert the text chunks into vector embeddings using OpenAI's embedding model. These embeddings represent the semantic meaning of each chunk, allowing us to perform similarity search later. The resulting vectors are stored in a FAISS vector database, which we save to Google Drive so the system can be reused without repeating the entire processing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngyOQp3CYhl_",
        "outputId": "cb8fb367-19c9-4181-819b-94b48d437d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bc1b32b623b4>:6: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding = OpenAIEmbeddings()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS vectorstore saved to Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# Import the embedding model and FAISS vector store from LangChain\n",
        "from langchain.embeddings import OpenAIEmbeddings  # Interface to OpenAI's text embedding API\n",
        "from langchain.vectorstores import FAISS  # Wrapper for FAISS-based similarity search\n",
        "\n",
        "# Initialize the OpenAI embedding model (default uses 'text-embedding-ada-002')\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# Create a FAISS vector store from the previously created document chunks\n",
        "# This indexes all_chunks using their semantic vector representations\n",
        "vectorstore = FAISS.from_documents(all_chunks, embedding)\n",
        "\n",
        "# Define the path in Google Drive where the FAISS index will be saved\n",
        "save_path = \"/content/drive/MyDrive/Project Work/RAG_Vs\"\n",
        "\n",
        "# Save the FAISS index and associated data locally to the specified path\n",
        "vectorstore.save_local(save_path)\n",
        "\n",
        "# Confirm successful saving of the vector store\n",
        "print(\"FAISS vectorstore saved to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgynzGn7juGu"
      },
      "source": [
        "**Reload FAISS Vector Store for Querying**\n",
        "\n",
        "In this step, we reload the previously saved FAISS vector store from Google Drive. We use OpenAI’s embedding model again to ensure consistency with the stored vectors, and enable allow_dangerous_deserialization=True since FAISS uses pickle-based files (safe here because the data is self-generated). Once loaded, we convert the vector store into a retriever, which will later be used to find the most relevant text chunks in response to user queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "69Mg38y6ZtA1"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass  # Useful for securely entering API keys if needed\n",
        "\n",
        "# Import OpenAI embeddings and FAISS vector store functionality from LangChain\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Initialize the embedding model using the OpenAI API key stored in environment variables\n",
        "# Ensure that OPENAI_API_KEY is already set via os.environ before this line\n",
        "embedding = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# Load the previously saved FAISS vector store from local storage\n",
        "# The 'allow_dangerous_deserialization=True' flag is required to safely load data stored with pickle\n",
        "loaded_vectorstore = FAISS.load_local(\n",
        "    folder_path=save_path,              # Path where the FAISS store was saved\n",
        "    embeddings=embedding,               # Embedding object to match chunk vectors\n",
        "    allow_dangerous_deserialization=True  # Caution: Use only with trusted data sources\n",
        ")\n",
        "\n",
        "# Convert the loaded vector store into a retriever\n",
        "# This object can now be used in RetrievalQA or similar pipelines to fetch relevant chunks given a query\n",
        "retriever = loaded_vectorstore.as_retriever()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRvpXzDTkBXh"
      },
      "source": [
        "**Set Up GPT-4 Question Answering Chain**\n",
        "\n",
        "In this step, we create a Retrieval-Augmented Generation (RAG) chain that connects GPT-4 to our vector store. When a question is asked, the retriever first finds the most relevant document chunks from the FAISS vector store. Then, GPT-4 uses those chunks as context to generate a structured, evidence-based answer. This setup allows us to ask clinical or research questions and receive context-aware responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1GSIhS9YeMsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a094cc-3b96-46ac-d615-c213b1c18d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b848d2cda4ba>:22: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm=ChatOpenAI(\n"
          ]
        }
      ],
      "source": [
        "# Import necessary components from LangChain\n",
        "from langchain.chains import RetrievalQA  # Builds a QA chain that retrieves documents and generates answers\n",
        "from langchain.prompts import PromptTemplate  # Used to create a custom prompt for more precise model guidance\n",
        "from langchain.chat_models import ChatOpenAI  # Wrapper for accessing OpenAI's GPT chat models\n",
        "\n",
        "# Define a custom prompt template for answering biomedical/surgical questions\n",
        "custom_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are a clinical research assistant tasked with answering surgical questions based on biomedical literature.\n",
        "\n",
        "Use the following retrieved context to answer the question. If the context does not contain exact numbers, use approximate reasoning and mention that. Always be specific and reference the supporting evidence when possible.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "# Construct a RetrievalQA chain using GPT-4 and the retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(\n",
        "        model_name=\"gpt-4\",  # Specify the LLM to use (here, GPT-4 via OpenAI)\n",
        "        openai_api_key=os.environ[\"OPENAI_API_KEY\"]  # Load API key securely from environment variable\n",
        "    ),\n",
        "    retriever=retriever,  # Pass in the FAISS-based retriever to fetch relevant chunks from your document set\n",
        "    chain_type_kwargs={\"prompt\": custom_prompt}  # Apply the custom prompt to guide how GPT-4 uses the retrieved context\n",
        ")\n",
        "\n",
        "# This custom RetrievalQA chain now:\n",
        "# 1. Accepts a clinical query.\n",
        "# 2. Retrieves relevant document chunks using semantic similarity.\n",
        "# 3. Feeds the context and question into GPT-4 using your instructive prompt.\n",
        "# 4. Returns a detailed, grounded answer (if possible) based on the available context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHQhJf0bkS2N"
      },
      "source": [
        "**Run a Clinical Query Using the RAG Pipeline**\n",
        "\n",
        "In this final step, we run a structured clinical query through the RAG pipeline. The retriever searches the vector store for the most relevant content from the uploaded PubMed articles, and GPT-4 generates a summarized, evidence-based response. This allows us to extract key insights (e.g., complications, cost impact, and patient-reported outcomes) without manually reviewing each paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adyQYbA_eC-Y",
        "outputId": "4ff2cfd1-42f5-4b2f-8724-f8a7a31785af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The context does not provide specific complications associated with increasing length of stay after microvascular breast reconstruction. However, it mentions that certain risk factors and comorbidities such as obesity, diabetes, malignancy history, operative time, a history of radiation therapy, smoking, and bilateral reconstruction may necessitate a longer length of stay. \n",
            "\n",
            "The context also does not provide specific details on how hospital costs increase with each additional day of stay. However, it suggests that a shortened length of stay is safe and effective, and that from a cost-utility perspective, a discharge on postoperative day 3 is the most advantageous.\n",
            "\n",
            "Regarding patient-reported outcomes, the context doesn't provide direct information. However, it mentions that an earlier discharge was supported not only from a cost perspective but also in terms of quality-adjusted life-years, implying that shorter hospital stays may lead to better patient-reported outcomes. \n",
            "\n",
            "Please note that these are approximations and the context does not provide specific numbers or details for these aspects.\n"
          ]
        }
      ],
      "source": [
        "query = \"What complications are associated with increasing length of stay after microvascular breast reconstruction? 1a. How do hospital costs increase with each additional day of stay? 1b. How does length of stay affect patient-reported outcomes?\"\n",
        "result = qa_chain.run(query)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDrLIdMTensL",
        "outputId": "3a6798e0-a4f6-4cff-abb0-38b82f717a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the systematic review, patient-reported outcomes were generally higher for autologous (tissue-based) breast reconstruction compared to implant-based reconstruction. Using the BREAST-Q validated measurement tool, patients who underwent autologous reconstruction reported higher satisfaction with their breasts and greater psychosocial well-being than those who underwent implant-based reconstruction. Differences in physical well-being between the two groups were less significant and the least significant difference was noted for sexual well-being. The EORTC-QLQ-BR23/C30 PROMs also noted similar trends. The SF-36 measure, however, noted virtually no difference between the two methods of reconstruction regarding similar quality of life domains. Therefore, from the patient perspective, autologous reconstruction is either equal to or superior to implant-based reconstruction. The context does not provide exact numbers for these outcomes.\n"
          ]
        }
      ],
      "source": [
        "query = \"How do patient-reported outcomes compare between implant-based and autologous (tissue-based) breast reconstruction?\"\n",
        "result = qa_chain.run(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIio4dAefefE",
        "outputId": "6b74a47c-fc74-4214-e826-416e595e1acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rates of postoperative complications overall between patients receiving DIEP vs TRAM flap surgery were fairly similar (5.3% and 5.5% respectively). However, wound dehiscence immediately postoperatively occurred significantly more in the TRAM flaps as compared to the DIEP flaps. Regarding costs, the total hospital charges to costs using cost-to-charge ratio were comparable between DIEP and TRAM flaps. In fact, contrary to the prevailing assumption, the study found that TRAM flaps are not more cost-effective than DIEP flaps. The total hospital charges to costs for patients in the DIEP and the TRAM subgroups were $29,775 and $28,466, respectively. These findings contradict the notion that TRAM flaps are less expensive procedures when compared to DIEP flaps.\n"
          ]
        }
      ],
      "source": [
        "query = \"Are TRAM flaps associated with higher complication rates and costs compared to DIEP flaps?\"\n",
        "result = qa_chain.run(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reOtc2DWfuN_",
        "outputId": "55a2ac57-9b0b-4926-c6b3-edfda752b4d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most important predictors of patient satisfaction in the BREAST-Q across the groups are:\n",
            "\n",
            "4a. DIEP flaps: Patient scores following DIEP flap surgery were reported to be high (mean score, 83) on the BREAST-Q abdominal well-being scale. This indicates that patients undergoing DIEP flap surgery generally had a good satisfaction rate (Context: \"Using the BREAST-Q abdominal well-being scale, patient scores following DIEP flap surgery (mean score, 83) were included in the breast health-related quality-adjusted life-year calculation\").\n",
            "\n",
            "4b. TRAM flaps: The context suggests that TRAM reconstruction was preferred over implant reconstruction, indicating a higher level of patient satisfaction with TRAM flaps (Context: \"Hu et al. (19) reported that TRAM reconstruction was preferred over implant in this regard\").\n",
            "\n",
            "4c. Implant-based reconstruction: The context suggests that there was less satisfaction with breast implant reconstruction when compared to autologous reconstruction methods like DIEP flaps and TRAM flaps (Context: \"All studies utilizing BREAST-Q reported statistically significant increases in ‘satisfaction with breast’ with autologous when compared to implant reconstruction\").\n",
            "\n",
            "4d. Total mastectomy without reconstruction: The context does not provide specific information regarding patient satisfaction in the BREAST-Q for total mastectomy without reconstruction.\n"
          ]
        }
      ],
      "source": [
        "query = \"What are the most important predictors of patient satisfaction in the BREAST-Q across the following groups: 4a. DIEP flaps 4b. TRAM flaps 4c. Implant-based reconstruction 4d. Total mastectomy without reconstruction\"\n",
        "result = qa_chain.run(query)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ9cshSIfQ0m",
        "outputId": "928c8f81-2b82-41a4-efaa-49bc170a5ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Query 1 ---\n",
            "What are the most important predictors of patient satisfaction in the BREAST-Q for DIEP flap reconstruction?\n",
            "\n",
            "Answer:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-26bb000bb66d>:11: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain.run(q)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The context does not provide specific predictors of patient satisfaction in the BREAST-Q for DIEP flap reconstruction. However, it does mention the use of the BREAST-Q abdominal well-being scale to measure patient scores following DIEP flap surgery. It also suggests that patient-centered care and patient input are important aspects of determining patient satisfaction. Therefore, it can be inferred that individual patient experiences and concerns, such as potential abdominal weakness, might play a significant role in patient satisfaction. However, without more specific information, this is an approximate interpretation.\n",
            "\n",
            "Top Retrieved Chunks:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-26bb000bb66d>:15: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = retriever.get_relevant_documents(q)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chunk 1:\n",
            "service using the BREAST-Q patient reported outcomes \n",
            "measure: A cohort study. J Plast Reconstr Aesthet Surg \n",
            "2016;69:1469-77. \n",
            "22. Tønseth KA, Hokland BM, Tindholdt TT , et al. Quality \n",
            "of life, patient satisfaction and cosmetic outcome after \n",
            "breast reconstruction using DIEP flap or expandable breast \n",
            "implant. J Plast Reconstr Aesthet Surg 2008;61:1188-94. \n",
            "23. Thorarinsson A, Fröjd V , Kölby L, et al. Long-T erm \n",
            "Health-Related Quality of Life after Breast Reconstruction: \n",
            "Comparing 4 Differe...\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "It is well known that patients choose prosthetic \n",
            "techniques, citing potential abdominal weakness \n",
            "as a concern. 24 Using the BREAST-Q abdominal \n",
            "well-being scale, patient scores following DIEP \n",
            "flap surgery (mean score, 83) were included in \n",
            "the breast health-related quality-adjusted life-\n",
            "year calculation to directly contrast with implant \n",
            "reconstructions (score, 100). Although results of \n",
            "the current study are in agreement with previous \n",
            "research that demonstrates the cost effectiveness \n",
            "of a...\n",
            "\n",
            "\n",
            "--- Query 2 ---\n",
            "What are the most important predictors of patient satisfaction in the BREAST-Q for TRAM flap reconstruction?\n",
            "\n",
            "Answer:\n",
            "The most important predictors of patient satisfaction in the BREAST-Q for TRAM flap reconstruction appear to be the choice of autologous reconstruction over implant reconstruction. The literature noted statistically significant increases in 'satisfaction with breast' with autologous reconstruction, including TRAM flaps, when compared to implant-based reconstruction. This was found to be true in both immediate and delayed procedures. However, it should be noted that the context does not provide exact figures or percentages regarding this satisfaction increase.\n",
            "\n",
            "Top Retrieved Chunks:\n",
            "\n",
            "Chunk 1:\n",
            "PROMs used to gauge mastectomy patients, a significant \n",
            "proportion utilized the BREAST-Q study (Figure 3).\n",
            "PROMs\n",
            "BREAST-Q\n",
            "Satisfaction with breast\n",
            "All studies utilizing BREAST-Q reported statistically \n",
            "significant increases in ‘satisfaction with breast’ with \n",
            "autologous when compared to implant reconstruction. Even \n",
            "after mixed-effects regression analysis by Santosa et al. (24), \n",
            "the increase was still statistically significant. Hu et al. (19) \n",
            "reported that TRAM reconstruction was preferred ove...\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "service using the BREAST-Q patient reported outcomes \n",
            "measure: A cohort study. J Plast Reconstr Aesthet Surg \n",
            "2016;69:1469-77. \n",
            "22. Tønseth KA, Hokland BM, Tindholdt TT , et al. Quality \n",
            "of life, patient satisfaction and cosmetic outcome after \n",
            "breast reconstruction using DIEP flap or expandable breast \n",
            "implant. J Plast Reconstr Aesthet Surg 2008;61:1188-94. \n",
            "23. Thorarinsson A, Fröjd V , Kölby L, et al. Long-T erm \n",
            "Health-Related Quality of Life after Breast Reconstruction: \n",
            "Comparing 4 Differe...\n",
            "\n",
            "\n",
            "--- Query 3 ---\n",
            "What are the most important predictors of patient satisfaction in the BREAST-Q for implant-based reconstruction?\n",
            "\n",
            "Answer:\n",
            "The most important predictors of patient satisfaction in the BREAST-Q for implant-based reconstruction appear to be satisfaction with the breast and psychosocial well-being. These were rated highly by the autologous group when compared to the implant-based reconstruction group. Physical well-being was less significant, and the least significant difference was noted for sexual well-being. It's important to note that these findings are based on the context provided, which suggests that autologous reconstruction is generally preferred over implant-based reconstruction. However, individual patient outcomes may vary.\n",
            "\n",
            "Top Retrieved Chunks:\n",
            "\n",
            "Chunk 1:\n",
            "PROMs used to gauge mastectomy patients, a significant \n",
            "proportion utilized the BREAST-Q study (Figure 3).\n",
            "PROMs\n",
            "BREAST-Q\n",
            "Satisfaction with breast\n",
            "All studies utilizing BREAST-Q reported statistically \n",
            "significant increases in ‘satisfaction with breast’ with \n",
            "autologous when compared to implant reconstruction. Even \n",
            "after mixed-effects regression analysis by Santosa et al. (24), \n",
            "the increase was still statistically significant. Hu et al. (19) \n",
            "reported that TRAM reconstruction was preferred ove...\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "Discussion\n",
            "With the increasing number of reconstructive options \n",
            "available to the patient and surgeon, and increasing survival \n",
            "rates of breast cancer patients, there is now an increasing \n",
            "number of factors outside of the surgical domain to consider \n",
            "for the surgeon when counseling the patient (26). This is \n",
            "complicated by the statistically significant heterogeneity of \n",
            "patients presenting, as evidenced by the baseline variables \n",
            "that were different between the two groups of patients \n",
            "analyzed (...\n",
            "\n",
            "\n",
            "--- Query 4 ---\n",
            "What are the most important predictors of patient satisfaction in the BREAST-Q for total mastectomy without reconstruction?\n",
            "\n",
            "Answer:\n",
            "The context does not provide specific predictors of patient satisfaction in the BREAST-Q for total mastectomy without reconstruction. However, it does mention that all studies utilizing BREAST-Q reported statistically significant increases in 'satisfaction with breast' with autologous when compared to implant reconstruction. This suggests that the type of reconstruction might influence patient satisfaction. Specifically, TRAM reconstruction was preferred over implant in this regard, according to Hu et al. (19). Furthermore, Jeevan et al. (20) noted statistically significant increases with those undergoing immediate LD, pedicled and free TRAM, DIEP and SIEA flaps when compared to implant-based reconstruction. Again, this suggests that the type of surgery and reconstruction can play a role in patient satisfaction. However, without more specific information about total mastectomy without reconstruction, it's impossible to identify the most important predictors of patient satisfaction in this context.\n",
            "\n",
            "Top Retrieved Chunks:\n",
            "\n",
            "Chunk 1:\n",
            "PROMs used to gauge mastectomy patients, a significant \n",
            "proportion utilized the BREAST-Q study (Figure 3).\n",
            "PROMs\n",
            "BREAST-Q\n",
            "Satisfaction with breast\n",
            "All studies utilizing BREAST-Q reported statistically \n",
            "significant increases in ‘satisfaction with breast’ with \n",
            "autologous when compared to implant reconstruction. Even \n",
            "after mixed-effects regression analysis by Santosa et al. (24), \n",
            "the increase was still statistically significant. Hu et al. (19) \n",
            "reported that TRAM reconstruction was preferred ove...\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "Snapshot of Satisfaction with Breast Cancer Procedures. \n",
            "Ann Surg Oncol 2015;22:361-9. \n",
            "12. Lee C, Sunu C, Pignone M. Patient-Reported Outcomes \n",
            "of Breast Reconstruction after Mastectomy: A Systematic \n",
            "Review. J Am Coll Surg 2009;209:123-33. \n",
            "13. Blazeby JM, Avery K, Sprangers M, et al. Health-related \n",
            "quality of life measurement in randomized clinical trials in \n",
            "surgical oncology. J Clin Oncol 2006;24:3178-86. \n",
            "14. Santosa KB, Qi J, Kim HM, et al. Long-term Patient-\n",
            "Table 6 Summary Tønseth et a...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "subqueries = [\n",
        "    \"What are the most important predictors of patient satisfaction in the BREAST-Q for DIEP flap reconstruction?\",\n",
        "    \"What are the most important predictors of patient satisfaction in the BREAST-Q for TRAM flap reconstruction?\",\n",
        "    \"What are the most important predictors of patient satisfaction in the BREAST-Q for implant-based reconstruction?\",\n",
        "    \"What are the most important predictors of patient satisfaction in the BREAST-Q for total mastectomy without reconstruction?\"\n",
        "]\n",
        "\n",
        "for i, q in enumerate(subqueries, 1):\n",
        "    print(f\"\\n--- Query {i} ---\\n{q}\")\n",
        "    print(\"\\nAnswer:\")\n",
        "    result = qa_chain.run(q)\n",
        "    print(result)\n",
        "\n",
        "    print(\"\\nTop Retrieved Chunks:\")\n",
        "    retrieved_docs = retriever.get_relevant_documents(q)\n",
        "    for j, doc in enumerate(retrieved_docs[:2]):  # show top 2 chunks\n",
        "        print(f\"\\nChunk {j+1}:\\n{doc.page_content[:500]}...\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}